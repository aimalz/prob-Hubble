{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating SNe II discovered by LSST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified from previous work done by Thomas de Jaeger in [de Jaeger et al. 2017](http://adsabs.harvard.edu/abs/2017ApJ...835..166D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "from scipy import integrate\n",
    "from scipy import interpolate\n",
    "from numpy import vectorize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_light=299792.458   # in km/s\n",
    "c_AA=299792458*1.0e10# in AA/s\n",
    "alpha_IMF=1.35       # Salpeter IMF: Salpeter et al. 1955 ApJ 121: 161\n",
    "z_max=1.2            # input('Givea value of the maximum redshift used :')\n",
    "z_sim=np.arange(0.01,z_max,0.01)\n",
    "fow_LSST=9.62        # field of view LSST in degrees^2\n",
    "delta_omega=fow_LSST*(math.pi/180)**2      # field of view LSST in str\n",
    "# calculating for r-band -> http://smtn-002.lsst.io/en/latest/\n",
    "h_erg = 6.63e-27     # Planck constant (erg.s)\n",
    "h = 0.70             # dimensionless Hubble constant\n",
    "H0 = 100.0 * h       # Hubble constant in Km/s/Mpc\n",
    "d_h=c_light/H0   # Hubble distance in Mpc   (70 km/s / Mpc)\n",
    "\n",
    "mag_lim={'u':23.60,'g':24.83,'r':24.38,'i':23.92,'z':23.35,'y':22.44} #mag lim 1 expo grizY\n",
    "#mag_lim_10=[26.1,27.4,27.5,26.8,26.1,24.9]   #mag lim stacked images after 10 years\n",
    "\n",
    "#cosmology\n",
    "omega_m=0.30\n",
    "omega_k=0.0\n",
    "omega_lambda=0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_z_distri(z):\n",
    "    return (1.0/math.sqrt(omega_m*((1+z)**3)+ omega_k*((1+z)**2) + omega_lambda))\n",
    "    e_z_int, e_z_int_err = integrate.quad(e_z_distri,0.,z)\n",
    "\n",
    "def r_com_distri(z):   ## dc in Pancho paper                # We define comoving distance for flat universe in Mpc\n",
    "    return (d_h*integrate.quad(e_z_distri,0.,z)[0])\n",
    "\n",
    "def d_lum_distri(z):                   # We define luminosity distance for flat universe in Mpc\n",
    "    return (r_com_distri(z)*(1+z))\n",
    "\n",
    "def d_mod_distri(z):                   # We define modulus distance for flat universe\n",
    "    return (5.0 * np.log10(d_lum_distri(z)*10**6/10))\n",
    "\n",
    "def madau_time(t):                   # We define t9 as Madeau et al 1998\n",
    "    return (13*pow((1+t),-1.5))\n",
    "\n",
    "def salpeter(M):\n",
    "    return (pow(M,-(1+alpha_IMF)))\n",
    "def Mass_tot(M):\n",
    "    return (M*pow(M,-(1+alpha_IMF)))\n",
    "\n",
    "a=3.4\n",
    "b=-0.3\n",
    "c=-3.5\n",
    "ro=0.016*0.73\n",
    "eta=-10\n",
    "B=2**(1-a/b)\n",
    "C=2**((b-a)/c)*5**(1-b/c)\n",
    "def SFR_Horiuchi(z):\n",
    "    return (ro*((1+z)**(a*eta)+((1+z)*1.0/B)**(b*eta)+((1+z)*1.0/C)**(c*eta))**(-0.1))\n",
    "def SNR_Horiuchi(z):\n",
    "    return (KII*SFR_Horiuchi(z))\n",
    "\n",
    "a1=0.0166 \n",
    "b1=0.1848 \n",
    "c1=1.9474 \n",
    "d1=2.6316 \n",
    "def SFR_Cole(z):\n",
    "    return (h*(a1+b1*z)/(1+(z/c1)**d1))\n",
    "def SNR_Cole(z):\n",
    "    return (KII*SFR_Cole(z))   \n",
    "\n",
    "a2=0.015 \n",
    "b2=2.7 \n",
    "c2=2.9\n",
    "d2=5.6 \n",
    "def SFR_Madau(z):\n",
    "    return (a2*((1+z)**b2/(1+((1+z)/c2)**d2)))\n",
    "def SNR_Madau(z):\n",
    "    return (KII*SFR_Madau(z)) \n",
    "\n",
    "def dust(z):\n",
    "    if z<3.3:\n",
    "        f_dust=0.95-0.28*z\n",
    "    else:\n",
    "        f_dust=0.02\n",
    "    return f_dust \n",
    "\n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "def e_z_LCDM(z):\n",
    "    return (1.0/math.sqrt(omega_m*((1+z)**3)+ omega_k*((1+z)**2) + omega_lambda))\n",
    "    e_z_int_LCDM, e_z_int_err_LCDM = integrate.quad(e_z_LCDM,0.,z)\n",
    "\n",
    "def r_com_LCDM(z):                   # We define comoving distance for flat universe in Mpc\n",
    "    return (d_h*integrate.quad(e_z_LCDM,0.,z)[0])\n",
    "\n",
    "def d_lum_LCDM(z):                   # We define luminosity distance for flat universe in Mpc\n",
    "    return (r_com_LCDM(z)*(1+z))\n",
    "\n",
    "def mu_LCDM(z):                   # We define modulus distance for flat universe\n",
    "    return (5.0 * np.log10(d_lum_LCDM(z)*10**6/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preliminaries\n",
    "\n",
    "## 1.1 LSST filter responses\n",
    "\n",
    "We load the LSST filter throughputs from https://github.com/lsst/throughputs/tree/master/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.sims.photUtils.Bandpass as Bandpass\n",
    "\n",
    "lsst={}\n",
    "x_func={}\n",
    "s_x={}\n",
    "dem_x={}\n",
    "filterlist = ('u', 'g', 'r', 'i', 'z', 'y')\n",
    "lsst_effl={'u':3654.9,'g':4800.3,'r':6222.0,'i':7540.6,'z':8682.1,'y':9916.6}\n",
    "filtercolors = {'u':'b', 'g':'c', 'r':'g', 'i':'orange', 'z':'r', 'y':'m'}\n",
    "\n",
    "for f in filterlist:\n",
    "    lsst[f] = Bandpass()\n",
    "    lsst[f].readThroughput('total_'+f+'.dat')\n",
    "\n",
    "    trans_file=np.loadtxt('total_'+f+'.dat')\n",
    "    lambda_filter=trans_file[:,0]*10     #in AA\n",
    "    s_x[f]=trans_file[:,1]\n",
    "    x_func[f]=interpolate.interp1d(lambda_filter,s_x[f])\n",
    "    dem_x[f]=integrate.simps(x_func[f](lambda_filter)*1.0/lambda_filter,lambda_filter) \n",
    "\n",
    "    plt.plot(lsst[f].wavelen, lsst[f].sb, color=filtercolors[f], lw=2, label='LSST %s' % (f))\n",
    "\n",
    "plt.xlabel('Wavelength [nm]')\n",
    "plt.ylabel('Throughput [0-1]')\n",
    "plt.title('LSST Throughput Curves')\n",
    "plt.legend(loc=(0.85, 0.5), fancybox=True, fontsize='smaller')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join('LSSTfilters.png'), format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 K-corrections\n",
    "\n",
    "We use [Dessart et al. 2013](http://esoads.eso.org/abs/2013MNRAS.433.1745D) models to measure K-corrections between bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Kcorrection(object):\n",
    "    def __init__(self):\n",
    "        self.array = np.empty((len(filterlist),len(filterlist),len(z_sim)))\n",
    "        self.interpolate ={}\n",
    "    \n",
    "    def __getitem__(self,(f1,f2,z)):\n",
    "        return self.array[filterlist.index(f1),filterlist.index(f2),z]\n",
    "\n",
    "    def __setitem__(self,(f1,f2,z),value):\n",
    "        self.array[filterlist.index(f1),filterlist.index(f2),z]=value\n",
    "    \n",
    "    def interpol(self,f1,f2):\n",
    "        if f1+f2 not in self.interpolate:\n",
    "            self.interpolate[f1+f2]=interpolate.interp1d(z_sim,self[f1,f2,:])  \n",
    "        return self.interpolate[f1+f2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take Dessart' model 50 days after explosion\n",
    "ascii=pd.read_table('m15mlt3/m15_du_sch_mlt3_FeC_mix0p4_18.fl',delim_whitespace=True,header=None)\n",
    "lambda_model=ascii[0].values\n",
    "flux_model=ascii[1].values\n",
    "\n",
    "F_spec_model_0=interpolate.interp1d(lambda_model,flux_model)\n",
    "\n",
    "Kcor=Kcorrection()\n",
    "m_lsst_za={}\n",
    "m_lsst_0={}\n",
    "            \n",
    "for i,zs in enumerate(z_sim):\n",
    "    lambda_model_obs=lambda_model*(1+zs)\n",
    "    flux_model_obs=flux_model/(1+zs)\n",
    "    F_spec_model_z=interpolate.interp1d(lambda_model_obs,flux_model_obs)\n",
    "    \n",
    "    for f in filterlist:\n",
    "        #comparison of F_spec_model_z and F_spec_model_0\n",
    "        n_lsst_za=integrate.simps(F_spec_model_z(lambda_filter)*x_func[f](lambda_filter)*lambda_filter,lambda_filter)   \n",
    "        m_lsst_za[f]=-2.5*(np.log10(n_lsst_za/dem_x[f]))-48.60+2.5*(np.log10(c_AA))\n",
    "        #Comparison of F_spec_model_z(SDSS) and F_spec_model_0(CSP)\n",
    "        n_lsst_0=integrate.simps(F_spec_model_0(lambda_filter)*x_func[f](lambda_filter)*lambda_filter,lambda_filter)   \n",
    "        m_lsst_0[f]=-2.5*(np.log10(n_lsst_0/dem_x[f]))-48.60+2.5*(np.log10(c_AA))\n",
    "\n",
    "    for j,f1 in enumerate(filterlist):\n",
    "        for k,f2 in enumerate(filterlist):\n",
    "            Kcor[f1,f2,i]=m_lsst_za[f1]-m_lsst_0[f2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Here we construct a K-correction term from all bands to r-band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kxr=np.zeros(len(z_sim))\n",
    "for i,zs in enumerate(z_sim):\n",
    "    #select the closest filter to r at a certain redshift\n",
    "    lambda_eff=lsst_effl['r']*(1+zs)    \n",
    "    ind_X = np.where(np.array(lsst_effl.values()) == find_nearest(lsst_effl.values(),lambda_eff) )[0][0]    \n",
    "    Kxr[i]=Kcor[lsst_effl.keys()[ind_X],'r',i]\n",
    "\n",
    "Kxr_func=interpolate.interp1d(z_sim,Kxr)\n",
    "\n",
    "for j,f1 in enumerate(filterlist):\n",
    "    plt.plot(z_sim,Kcor.interpol(f1,'r')(z_sim),filtercolors[f1])\n",
    "plt.plot(z_sim,Kxr_func(z_sim),'black')\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('Kxr')\n",
    "plt.ylim(-2,2)\n",
    "plt.legend(('u->r','g->r','r->r','i->r','z->r','y->r'),loc=3,markerscale=0.5,prop={'size':15},ncol=2) \n",
    "plt.show()\n",
    "\n",
    "#Final Kcorrections fron x to r in Kx_r and Kxr_func\n",
    "# r->r if zs <= 0.105:\n",
    "# i->r if zs > 0.105 and zs <= 0.303:\n",
    "# z->r if zs > 0.303 and zs <= 0.494:\n",
    "# y->r if zs > 0.494:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculating SNII rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will basically apply the approach by [Forster et al. 2006](http://adsabs.harvard.edu/abs/2006MNRAS.368.1893F)/[Strogler et al. 2004](http://adsabs.harvard.edu/abs/2004ApJ...613..200S) adapted to SNe II following [Botticella et al. 2012](http://adsabs.harvard.edu/abs/2012A%26A...537A.132B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The rate of SNe II per unit time per unit comoving volume (RII) is given by the star formation rate (SFR) per unit time per unit comoving volume convolved with the number of stars crearted that will explode as SNe II (which we will estimate assuming a [Salpeter et al. (1955)](http://adsabs.harvard.edu/abs/1955ApJ...121..161S) IMF and their progenitors are stars from 8 to 25 solar masses)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/snr_ii.png\" alt=\"snr_ii\" style=\"width: 150px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Calculating the fraction of stars that explode as SN II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/fraction.png\" alt=\"fraction\" style=\"width: 180px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_min=8\n",
    "mass_max=25\n",
    "\n",
    "KII=integrate.quad(salpeter,mass_min,mass_max)[0]/(integrate.quad(Mass_tot,0.1,100.))[0]\n",
    "print(KII)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Calculating SFR\n",
    "\n",
    "As an example, we will use 3 different SFR evolutions with redshift: [Cole et al. (2001)](http://adsabs.harvard.edu/abs/2001MNRAS.326..255C), [Horiuchi et al. (2011)](http://adsabs.harvard.edu/abs/2011ApJ...738..154H), and [Madau et al. (2014)](http://adsabs.harvard.edu/abs/2014ARA%26A..52..415M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_Horiuchi_vect=vectorize(SFR_Horiuchi)\n",
    "SFR_Cole_vect=vectorize(SFR_Cole)\n",
    "SFR_Madau_vect=vectorize(SFR_Madau)\n",
    "\n",
    "plt.plot(z_sim,np.log10(SFR_Horiuchi_vect(z_sim)),'g',z_sim,np.log10(SFR_Cole_vect(z_sim)),'k',z_sim,np.log10(SFR_Madau_vect(z_sim)),'r')\n",
    "plt.legend(('Horiuchi','Cole','Madau'))\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('log(SFR) [h-1 M_solar yr-1 Mpc-3]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_Horiuchi_vect=vectorize(SNR_Horiuchi)\n",
    "SNR_Cole_vect=vectorize(SNR_Cole)\n",
    "SNR_Madau_vect=vectorize(SNR_Madau)\n",
    "\n",
    "plt.plot(z_sim,np.log10(SNR_Horiuchi_vect(z_sim)),'g',z_sim,np.log10(SNR_Cole_vect(z_sim)),'k',z_sim,np.log10(SNR_Madau_vect(z_sim)),'r')\n",
    "plt.legend(('Horiuchi','Cole','Madau'))\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('log SNR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Example with SN II 2005J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 At which redshift SN 2005J would not be detected with LSST?\n",
    "We will first take SN II 2005J as a reference and assume that all SNe II are like 05J. We simulate its r-band light curve at different redshifts and see that at z=0.39 it would be below the LSST detections limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD_explosion=2453382.78\n",
    "JD_ref=2453000\n",
    "z_cmb=4183./c_light\n",
    "err_z_cmb=150./c_light\n",
    "\n",
    "SN_photo=pd.read_table('05J/sn2005j.out_r_swope',delim_whitespace=True,header=None)\n",
    "SN_epoch=SN_photo[0].values+JD_ref-JD_explosion\n",
    "mag_r=SN_photo[1].values\n",
    "dmag_r=SN_photo[2].values\n",
    "\n",
    "M_SN_r=mag_r-5*np.log10(d_lum_distri(z_cmb))-25\n",
    "dM_SN_r=np.sqrt(dmag_r**2+(np.array(err_z_cmb)*(5*(1+np.array(z_cmb))*1.0/(np.array(z_cmb)*(1+np.array(z_cmb)*1.0/2)*np.log10(10))))**2)\n",
    "\n",
    "m_sn=np.zeros(shape=(len(SN_epoch),len(z_sim)))\n",
    "for t,snep in enumerate(SN_epoch):\n",
    "    for z,zs in enumerate(z_sim):\n",
    "        m_sn[t,z]=M_SN_r[t]+d_mod_distri(zs)+Kxr_func(zs)\n",
    "for z,zs in enumerate(z_sim):\n",
    "    plt.plot(SN_epoch,m_sn[:,z]) \n",
    "    if min(m_sn[:,z]) > mag_lim['r']:\n",
    "        print('Not visible from z='+str(zs))\n",
    "        break\n",
    "plt.ylim(28,15)\n",
    "plt.axhline(mag_lim['r'], color='k', linestyle='--')\n",
    "plt.xlabel('MJD [days]')\n",
    "plt.ylabel('Apparent magnitude [mag]')\n",
    "plt.title('SN 2005J at several redshifts')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(SN_epoch,M_SN_r, linestyle='--') \n",
    "plt.ylim(np.max(M_SN_r)+0.2,np.min(M_SN_r)-0.2)\n",
    "plt.title('SN 2005J')\n",
    "plt.ylabel('Absolute magnitude [mag]')\n",
    "plt.xlabel('MJD [days]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 How many SNe II (2005J-like) would the LSST discover in 1 year?\n",
    "\n",
    "First, we compare our $m(t,z)$ with $m_{lim}$ of the LSST camera to obtain $\\Delta_{t}(z)$,  the probability of detecting (the peak of) a SN at a given redshift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_min=[0]*len(z_sim)\n",
    "t_max=[0]*len(z_sim)\n",
    "t_max_2=[0]*len(z_sim)\n",
    "delta_t_redshift=[0]*len(z_sim) #delta t corrected by redshift\n",
    "epoch_model_z=[0]*len(SN_epoch)\n",
    "\n",
    "for i,zs in enumerate(z_sim):\n",
    "    epoch_model_z=SN_epoch*(1+zs)  #1+z factor for time dilation\n",
    "    if min(m_sn[:,i][:])<mag_lim['r']:\n",
    "        t_min[i]=epoch_model_z[min(np.where(m_sn[:,i]<=mag_lim['r'])[0])]\n",
    "        o=set(np.where(epoch_model_z>=t_min[i])[0])   #index of the last t>t_min\n",
    "        p=set(np.where(m_sn[:,i]<=mag_lim['r'])[0])        #index at which we see the SN\n",
    "        q=(list(o-p))                                 #all the indeces where we see the peak\n",
    "        if q==[]:\n",
    "            t_max[i]=epoch_model_z[max(np.where(m_sn[:,i]<=mag_lim['r'])[0])]\n",
    "            delta_t_redshift[i]=t_max[i]-t_min[i]\n",
    "        else:\n",
    "            t_max[i]=epoch_model_z[min(q)]\n",
    "            t_max_2[i]=epoch_model_z[max(q)]\n",
    "            delta_t_redshift[i]=(t_max[i]-t_min[i])+(max(epoch_model_z)-t_max_2[i])#le SBO+ rest of curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate the number of detected SNe II per unit of redshift, $dN/dz$. From Equations 2 and 5 of Forster et al. (2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dV_dz_dW=np.zeros(len(z_sim))\n",
    "\n",
    "#############\n",
    "survey_length=1.0   #in years\n",
    "#############\n",
    "\n",
    "dn_dz_Horiuchi=[0]*len(z_sim)   \n",
    "dn_dz_Cole=[0]*len(z_sim)      \n",
    "dn_dz_Madau=[0]*len(z_sim)      \n",
    "\n",
    "for i,zs in enumerate(z_sim):\n",
    "    dV_dz_dW[i]=(pow(r_com_distri(zs),2)*d_h*e_z_distri(zs))                 #dV(z) is the volume per unit redshift being surveyed\n",
    "\n",
    "    #total observing time multiplied by the probability of detecting a SN\n",
    "    dn_dz_Horiuchi[i]=SNR_Horiuchi(zs)/(1.+zs)*dV_dz_dW[i]*delta_omega*((delta_t_redshift[i])/365.25)*survey_length #In yr (SNR in yr)     #dn/dz is the SN per unit of redshift, comovil volume, solid angle and fied of view\n",
    "    dn_dz_Cole[i]=SNR_Cole(zs)/(1+zs)*dV_dz_dW[i]*delta_omega*((delta_t_redshift[i])/365.25)*survey_length #In yr (SNR in yr)          #dn/dz is the SN per unit of redshift, comovil volume, solid anfle and fied of view\n",
    "    dn_dz_Madau[i]=SNR_Madau(zs)/(1+zs)*dV_dz_dW[i]*delta_omega*((delta_t_redshift[i])/365.25)*survey_length #In yr (SNR in yr)        #dn/dz is the SN per unit of redshift, comovil volume, solid anfle and fied of view\n",
    "                               \n",
    "    \n",
    "plt.plot(z_sim,dn_dz_Horiuchi,'b',z_sim,dn_dz_Cole,'c',z_sim,dn_dz_Madau,'r')\n",
    "plt.title('The number of detected SNe II per unit of redshift interval')\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('num SN ')\n",
    "plt.legend(('Horiuchi','Cole','Madau'))\n",
    "plt.show()\n",
    "\n",
    "# We integrate for all the redshift to have the number of SN \n",
    "print('Num. SNe Horiuchi: '+str(int(np.sum(dn_dz_Horiuchi))))\n",
    "for i,zs in enumerate(z_sim):\n",
    "    if dn_dz_Horiuchi[i] == 0.0:\n",
    "        print('No SNe II from z='+str(zs))\n",
    "        break\n",
    "        \n",
    "print('Num. SNe Cole:     '+str(int(np.sum(dn_dz_Cole))))\n",
    "for i,zs in enumerate(z_sim):\n",
    "    if dn_dz_Cole[i] == 0.0:\n",
    "        print('No SNe II from z='+str(zs))\n",
    "        break\n",
    "        \n",
    "print('Num. SNe Madau:     '+str(int(np.sum(dn_dz_Madau))))\n",
    "for i,zs in enumerate(z_sim):\n",
    "    if dn_dz_Madau[i] == 0.0:\n",
    "        print('No SNe II from z='+str(zs))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Example with a model of a 'typical' SN II\n",
    "\n",
    "Instead of assuming that all SNe II are like SN 2005J, we will use the spectral model of [Dessart et al. (2013](http://adsabs.harvard.edu/abs/2013MNRAS.433.1745D) which is anchored to SN II 1999em. \n",
    "\n",
    "This SN is a bit fainter compared to SN 2005J ($M_{99em}=-16.6$; $M_{05J}=-17.2$), so we expect to find a distribution with a cutout at lower redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This loads all models in lam,flux_model\n",
    "model=pd.read_table('m15mlt3/m15_du_sch_mlt3_FeC_mix0p4_list',delim_whitespace=True,header=None)\n",
    "filename=model[0].values\n",
    "epoch=model[1].values\n",
    "\n",
    "lam_model=len(epoch)*[0]\n",
    "flux_model=len(epoch)*[0]\n",
    "\n",
    "puta99em=pd.read_table('sn1999em.out_R',delim_whitespace=True,header=None)\n",
    "ep_99em=puta99em[0].values-51476.5\n",
    "mag_99em=puta99em[1].values\n",
    "F_99em=interpolate.interp1d(ep_99em,mag_99em)\n",
    "\n",
    "mapp_99em=len(filename)*[0]\n",
    "Mabs_99em=len(filename)*[0]\n",
    "for i,fname in enumerate(filename):\n",
    "    if i ==0:\n",
    "        ascii=pd.read_table('m15mlt3/'+fname+'.fl',delim_whitespace=True,header=None)\n",
    "        lam_model[i]=ascii[0].values\n",
    "        flux_model[i]=ascii[1].values\n",
    "        \n",
    "        #mangling\n",
    "        F_spec_model_z=interpolate.interp1d(lam_model[i]/1.002392,flux_model[i]*1.002392)\n",
    "        n_obs=integrate.simps(F_spec_model_z(lambda_filter)*x_func['r'](lambda_filter)*lambda_filter,lambda_filter)\n",
    "        m_obs_r=-2.5*np.log10(n_obs/dem_x['r'])-48.60+2.5*(np.log10(c_AA))\n",
    "        factor=10**(-0.4*(F_99em(epoch[i])-m_obs_r))\n",
    "                \n",
    "    ascii=pd.read_table('m15mlt3/'+fname+'.fl',delim_whitespace=True,header=None)\n",
    "    lam_model[i]=ascii[0].values\n",
    "    flux_model[i]=ascii[1].values*factor\n",
    "    \n",
    "    F_spec_model_z=interpolate.interp1d(lam_model[i],flux_model[i])\n",
    "    num=integrate.simps(F_spec_model_z(lambda_filter)*x_func['r'](lambda_filter)*lambda_filter,lambda_filter)\n",
    "    mapp_99em[i]=-2.5*np.log10((num/dem_x['r']))-48.60+2.5*(np.log10(c_AA))\n",
    "    Mabs_99em[i]=mapp_99em[i]-mu_LCDM(0.002392)\n",
    "\n",
    "    plt.plot(lam_model[i],flux_model[i])\n",
    "\n",
    "plt.xlim(1000,15000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sn_model=np.zeros(shape=(len(epoch),len(z_sim)))\n",
    "for i,snep in enumerate(epoch):\n",
    "    for t,zs in enumerate(z_sim):\n",
    "        m_sn_model[i,t]=Mabs_99em[i]+d_mod_distri(zs)+Kxr_func(zs)\n",
    "\n",
    "for i,zs in enumerate(z_sim):\n",
    "    plt.plot(epoch,m_sn_model[:,i]) #M_SN_r,)#\n",
    "    if min(m_sn[:,i]) > mag_lim['r']:\n",
    "        print('Not visible from z='+str(zs))\n",
    "        break\n",
    "#plt.ylim(np.max(m_sn_model)+0.2,np.min(m_sn_model)-0.2)\n",
    "plt.ylim(30,16)\n",
    "plt.xlim(0.,450)\n",
    "plt.axhline(mag_lim['r'], color='k', linestyle='--')\n",
    "plt.xlabel('MJD [days]')\n",
    "plt.ylabel('Apparent magnitude [mag]')\n",
    "plt.title('Luc at several redshifts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 How many SNe II (Dessart-like) would the LSST discover in 1 year?\n",
    "\n",
    "First, we compare our $m(t,z)$ with $m_{lim}$ of the LSST camera to obtain $\\Delta_{t}(z)$,  the probability of detecting (the peak of) a SN at a given redshift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_min=[0]*len(z_sim)\n",
    "t_max=[0]*len(z_sim)\n",
    "t_max_2=[0]*len(z_sim)\n",
    "delta_t_redshift=[0]*len(z_sim) #delta t corrected by redshift\n",
    "epoch_model_z=[0]*len(epoch)\n",
    "\n",
    "for i,zs in enumerate(z_sim):\n",
    "    epoch_model_z=epoch*(1+zs)  #1+z factor for time dilation\n",
    "    if min(m_sn_model[:,i][:])<mag_lim['r']:\n",
    "        t_min[i]=epoch_model_z[min(np.where(m_sn_model[:,i]<=mag_lim['r'])[0])]\n",
    "        o=set(np.where(epoch_model_z>=t_min[i])[0])              #index of the last t>t_min\n",
    "        p=set(np.where(m_sn_model[:,i]<=mag_lim['r'])[0])        #index at which we see the SN\n",
    "        q=(list(o-p))                                            #all the indeces where we see the peak\n",
    "        if q==[]:\n",
    "            t_max[i]=epoch_model_z[max(np.where(m_sn_model[:,i]<=mag_lim['r'])[0])]\n",
    "            delta_t_redshift[i]=t_max[i]-t_min[i]\n",
    "        else:\n",
    "            t_max[i]=epoch_model_z[min(q)]\n",
    "            t_max_2[i]=epoch_model_z[max(q)]\n",
    "            delta_t_redshift[i]=(t_max[i]-t_min[i])+(max(epoch_model_z)-t_max_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dV_dz_dW=np.zeros(len(z_sim))\n",
    "\n",
    "#############\n",
    "survey_length=1.0   #in years\n",
    "#############\n",
    "\n",
    "dn_dz_Horiuchi=[0]*len(z_sim)   \n",
    "dn_dz_Cole=[0]*len(z_sim)      \n",
    "dn_dz_Madau=[0]*len(z_sim)      \n",
    "for i,zs in enumerate(z_sim):\n",
    "    dV_dz_dW[i]=(pow(r_com_distri(zs),2)*d_h*e_z_distri(zs))                 #dV(z) is the volume per unit redshift being surveyed\n",
    "\n",
    "    dn_dz_Horiuchi[i]=SNR_Horiuchi(zs)/(1.+zs)*dV_dz_dW[i]*delta_omega*((delta_t_redshift[i])/365.25)*survey_length #In yr (SNR in yr)     #dn/dz is the SN per unit of redshift, comovil volume, solid angle and fied of view\n",
    "    dn_dz_Cole[i]=SNR_Cole(zs)/(1+zs)*dV_dz_dW[i]*delta_omega*((delta_t_redshift[i])/365.25)*survey_length #In yr (SNR in yr)          #dn/dz is the SN per unit of redshift, comovil volume, solid anfle and fied of view\n",
    "    dn_dz_Madau[i]=SNR_Madau(zs)/(1+zs)*dV_dz_dW[i]*delta_omega*((delta_t_redshift[i])/365.25)*survey_length #In yr (SNR in yr)        #dn/dz is the SN per unit of redshift, comovil volume, solid anfle and fied of view                               \n",
    "    \n",
    "plt.plot(z_sim,dn_dz_Horiuchi,'b',z_sim,dn_dz_Cole,'c',z_sim,dn_dz_Madau,'r')\n",
    "plt.title('The number of detected SNe II per unit of redshift interval')\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('num SN ')\n",
    "plt.legend(('Horiuchi','Cole','Madau'))\n",
    "plt.show()\n",
    "\n",
    "# We integrate for all the redshift to have the number of SN \n",
    "print('Num. SNe Horiuchi: '+str(int(np.sum(dn_dz_Horiuchi))))\n",
    "for i,zs in enumerate(z_sim):\n",
    "    if dn_dz_Horiuchi[i] == 0.0:\n",
    "        print('No SNe II from z='+str(zs))\n",
    "        break\n",
    "        \n",
    "print('Num. SNe Cole:     '+str(int(np.sum(dn_dz_Cole))))\n",
    "for i,zs in enumerate(z_sim):\n",
    "    if dn_dz_Cole[i] == 0.0:\n",
    "        print('No SNe II from z='+str(zs))\n",
    "        break\n",
    "        \n",
    "print('Num. SNe Madau:     '+str(int(np.sum(dn_dz_Madau))))\n",
    "for i,zs in enumerate(z_sim):\n",
    "    if dn_dz_Madau[i] == 0.0:\n",
    "        print('No SNe II from z='+str(zs))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Example with a CSP-like simulated sample of SNe II\n",
    "\n",
    "Finally, we will use a a sample of 10,000 SNe, simulated using MCMC on real parameters of CSP SNe II. We will put each at 100 random redshifts form 0.01 to 1.20, so we will have 1,000,000 SNe.\n",
    "\n",
    "Note that what we also change here is that we will consider the magnitude at the end of the plateau phase. This is becuase in SNII cosmology, we do not standardize the magnitude at peak but either the magnitude at around the center of the plateau (for spectroscopic methods), or the length/brightness-decline of the plateu (for photometric methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survey_length=1.0\n",
    "\n",
    "##simulation file:\n",
    "MC_var=np.loadtxt('mc_var.dat').transpose()\n",
    "\n",
    "Mabs_V_MC=MC_var[0] #M at the end of the plateau\n",
    "s2_MC=MC_var[1]     #slope of the plateau\n",
    "B_V_MC=MC_var[2]    #color at the end of the plateau\n",
    "Pd_MC=MC_var[3]     #plateau duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will put these 1000 SNe at a random redshifts\n",
    "\n",
    "N_SNe=len(Mabs_V_MC)\n",
    "\n",
    "z_random=np.sort(np.random.random(100)*max(z_sim-0.04)+0.04)\n",
    "\n",
    "m_SN=np.zeros((N_SNe,len(z_random)))\n",
    "Pd_SN=np.zeros((N_SNe,len(z_random)))\n",
    "delta_t_SN=np.zeros((N_SNe,len(z_random)))\n",
    "\n",
    "for i,zs in enumerate(z_random):\n",
    "    m_SN[:,i]=mu_LCDM(zs)+Mabs_V_MC+Kxr_func(zs)\n",
    "    Pd_SN[:,i]=Pd_MC*(1+zs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the 'distribution' of apparent magnitudes AT THE END OF THE PLATEAU PHASE for the first 2000 (over 1.000,000) SNe II look at differnet redshifts. \n",
    "\n",
    "Those 'jumps' happen at redshifts where the best K-correction changes the observed filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    plt.plot(z_random,m_SN[i,:],alpha=0.9,linewidth=0.1,color='b')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('m$_{end}$')\n",
    "plt.ylim(30,18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we measure $\\Delta_t(z)$, selecting different magnitude limit depending on the filter we use for observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range((N_SNe)):\n",
    "    for i in range(len(z_random)):\n",
    "        if z_random[i]<=0.3:           #V_swope would be converted to r_LSST                       \n",
    "            if m_SN[j,i]<mag_lim['r']:\n",
    "                delta_t_SN[j,i]=Pd_SN[j,i]\n",
    "        elif (z_random[i]>0.3) and (z_random[i]<=0.57) :  #V_swope would be i_LSST\n",
    "            if m_SN[j,i]<mag_lim['i']:\n",
    "                delta_t_SN[j,i]=Pd_SN[j,i]\n",
    "        elif (z_random[i]>0.57) and (z_random[i]<=0.78) : #V_swope would be z_LSST\n",
    "            if m_SN[j,i]<mag_lim['z']:\n",
    "                delta_t_SN[j,i]=Pd_SN[j,i]\n",
    "        elif (z_random[i]>0.78) :      #V_swope would be y_LSST\n",
    "            if m_SN[j,i]<mag_lim['y']:\n",
    "                delta_t_SN[j,i]=Pd_SN[j,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: this may be improved by carrying the distribution of delta_t_SN at each redshift, instead of simply measuring the average at each redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t_SN_tot=np.zeros((len(z_random)))\n",
    "for i in range(len(z_random)):\n",
    "    delta_t_SN_tot[i]=sum(delta_t_SN[:,i])\n",
    "\n",
    "delta_t_SN_tot=delta_t_SN_tot/N_SNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dV_dz_dW=np.zeros(len(z_random))\n",
    "\n",
    "dn_dz_Horiuchi=np.zeros(len(z_random)) \n",
    "dn_dz_Cole=np.zeros(len(z_random))\n",
    "dn_dz_Madau=np.zeros(len(z_random))\n",
    "\n",
    "for i in range(len(z_random)):\n",
    "    dV_dz_dW[i]=(pow(r_com_LCDM(z_random[i]),2)*d_h*e_z_LCDM(z_random[i]))    #dV(z) is the volume per unit redshift being surveyed\n",
    "\n",
    "    dn_dz_Horiuchi[i]=SNR_Horiuchi(z_random[i])/(1+z_random[i])*dV_dz_dW[i]*delta_omega*(delta_t_SN_tot[i]/365.25)*survey_length #In yr (SNR in yr)  #dn/dz is the SN per unit of redshift, comovil volume, solid angle and fied of view\n",
    "    dn_dz_Cole[i]    =SNR_Cole(z_random[i])    /(1+z_random[i])*dV_dz_dW[i]*delta_omega*(delta_t_SN_tot[i]/365.25)*survey_length #In yr (SNR in yr)  #dn/dz is the SN per unit of redshift, comovil volume, solid anfle and fied of view\n",
    "    dn_dz_Madau[i]   =SNR_Madau(z_random[i])   /(1+z_random[i])*dV_dz_dW[i]*delta_omega*(delta_t_SN_tot[i]/365.25)*survey_length #In yr (SNR in yr)  #dn/dz is the SN per unit of redshift, comovil volume, solid anfle and fied of view                               \n",
    "\n",
    "z_random,dn_dz_Horiuchi,dn_dz_Cole,dn_dz_Madau = zip(*sorted(zip(z_random,dn_dz_Horiuchi,dn_dz_Cole,dn_dz_Madau)))\n",
    "\n",
    "plt.plot(z_random,np.array(dn_dz_Cole),'c',z_random,np.array(dn_dz_Horiuchi),'b',z_random,np.array(dn_dz_Madau),'r')\n",
    "plt.title('The number of detected SNe II per unit of redshift interval')\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('num SN ')\n",
    "plt.legend(('Horiuchi','Cole','Madau'))\n",
    "plt.show()\n",
    "\n",
    "# We integrate for all the redshift to have the number of SN \n",
    "print('Num. SNe Horiuchi: '+str(int(np.sum(dn_dz_Horiuchi))))\n",
    "print('Num. SNe Cole:     '+str(int(np.sum(dn_dz_Cole))))    \n",
    "print('Num. SNe Madau:     '+str(int(np.sum(dn_dz_Madau))))\n",
    "z_tot_Madau=[]\n",
    "for i,zs in enumerate(z_sim):\n",
    "    if dn_dz_Madau[i] == 0.0:\n",
    "        print('No SNe II from z='+str(zs))\n",
    "        break\n",
    "\n",
    "z_random,dn_dz_Horiuchi,dn_dz_Cole,dn_dz_Madau = zip(*sorted(zip(z_random,dn_dz_Horiuchi,dn_dz_Cole,dn_dz_Madau)))\n",
    "z_tot_Madau=[]\n",
    "for i,zs in enumerate(z_random):\n",
    "    for j in range((int(round(dn_dz_Madau[i],0)))):\n",
    "        z_tot_Madau.append(zs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found the shape of the distribution, below one can create the final distribution by giving the total number of SNe II (with no selection effects) that LSST is supposed to found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SNe_HD=input(\"Number of SNe for the Hubble diagram: \")\n",
    "z_SNe_HD=np.random.choice(z_tot_Madau, N_SNe_HD, replace=True)\n",
    "\n",
    "plt.hist(z_SNe_HD,color='blue',alpha=0.9,label='Single-visit')\n",
    "plt.legend(loc=1,markerscale=0.5,prop={'size':12},ncol=2)\n",
    "#plt.xlim(0,1.2)\n",
    "plt.xlabel('redshift')\n",
    "plt.ylabel('SN ')\n",
    "plt.tick_params(axis='both', which='major', labelsize=13)\n",
    "plt.savefig('LSST_distribution.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
