{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock Data Pipeline\n",
    "\n",
    "Alex Malz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import daft\n",
    "import numpy as np\n",
    "import bisect\n",
    "import astropy.cosmology as cosmology\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc(\"font\", family=\"serif\", size=12)\n",
    "rc(\"text\", usetex=True)\n",
    "# from scipy.stats import norm\n",
    "# import emcee\n",
    "# from datetime import datetime\n",
    "\n",
    "colors = 'rbgcymk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[abstract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize the PGM\n",
    "pgm = daft.PGM([5, 6], origin=[0, 0])\n",
    "\n",
    "#desired hyperparameters\n",
    "pgm.add_node(daft.Node(\"cosmology\", r\"$\\vec{\\theta}$\", 1., 5.5))\n",
    "pgm.add_node(daft.Node(\"dist\", r\"$\\underline{\\phi}$\", 2.5, 5.5))\n",
    "#pgm.add_node(daft.Node(\"rates\", r\"$\\vec{R}$\", 3., 5.5, fixed=True))\n",
    "\n",
    "#latent variables/parameters\n",
    "pgm.add_node(daft.Node(\"distance\", r\"$\\mu_{n}$\", 1., 4.))\n",
    "pgm.add_node(daft.Node(\"redshift\", r\"$z_{n}$\", 2., 4.5))\n",
    "pgm.add_node(daft.Node(\"type\", r\"$t_{n}$\", 3., 4.5))\n",
    "\n",
    "#data\n",
    "pgm.add_node(daft.Node(\"lightcurve\", r\"$\\underline{\\ell}_{n}$\", 1.5, 3., observed=True))\n",
    "pgm.add_node(daft.Node(\"photometry\", r\"$\\vec{m}_{n}$\", 3., 3., observed=True))\n",
    "\n",
    "# Add in the edges.\n",
    "pgm.add_edge(\"dist\", \"type\")\n",
    "pgm.add_edge(\"cosmology\", \"distance\")\n",
    "pgm.add_edge(\"dist\", \"redshift\")\n",
    "pgm.add_edge(\"redshift\", \"distance\")\n",
    "#pgm.add_edge(\"distance\", \"photometry\")\n",
    "pgm.add_edge(\"distance\", \"lightcurve\")\n",
    "pgm.add_edge(\"redshift\", \"photometry\")\n",
    "pgm.add_edge(\"redshift\", \"lightcurve\")\n",
    "pgm.add_edge(\"type\", \"lightcurve\")\n",
    "\n",
    "# plates\n",
    "pgm.add_plate(daft.Plate([0.5, 2., 3., 3.], label=r\"$n = 1, \\cdots, N$\"))\n",
    "\n",
    "# Render and save.\n",
    "pgm.render()\n",
    "pgm.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing true parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[the true redshift-dependent type rate distribution, with plot of three functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "types = ['Ia', 'Ibc', 'II']#{'a': 0, 'b': 1, 'c': 2}\n",
    "n_types = len(types)\n",
    "frac_types = np.array([0.2, 0.3, 0.5])\n",
    "assert np.isclose(np.sum(frac_types), 1.)\n",
    "\n",
    "n_zs = 20\n",
    "min_z = 0.01\n",
    "max_z = 1.\n",
    "z_bins = np.linspace(min_z, max_z, num=n_zs + 1, endpoint=True)\n",
    "z_difs = z_bins[1:] - z_bins[:-1]\n",
    "z_dif = np.mean(z_difs)\n",
    "z_range = max_z - min_z\n",
    "z_mids = (z_bins[1:] + z_bins[:-1]) / 2.\n",
    "\n",
    "n_of_z = np.zeros((n_types, n_zs))\n",
    "n_of_z[0] += sps.norm(loc = 0.75, scale = 0.5).pdf(z_mids)\n",
    "n_of_z[1] += sps.norm(loc = 0.5, scale = 0.5).pdf(z_mids)\n",
    "n_of_z[2] += sps.norm(loc = 0.25, scale = 0.5).pdf(z_mids)\n",
    "n_of_z /= np.sum(n_of_z * z_difs[np.newaxis, :], axis=1)[:, np.newaxis]\n",
    "\n",
    "true_n_of_z = frac_types[:, np.newaxis] * np.array(n_of_z)# / z_range\n",
    "true_n_of_z /= np.sum(true_n_of_z * z_difs[np.newaxis, :])\n",
    "assert np.isclose(np.sum(true_n_of_z * z_difs[np.newaxis, :]), 1.)\n",
    "\n",
    "for t in range(n_types):\n",
    "    plt.plot(z_mids, true_n_of_z[t], color=colors[t], label=types[t])\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'relative rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[samples of t, z from the true redshift-dependent type rate distribution, with histograms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_discrete(dist, N):\n",
    "    out_info = []\n",
    "    norm_dist = dist * z_difs[np.newaxis, :]\n",
    "    assert np.isclose(np.sum(norm_dist), 1.)\n",
    "    dist_shape = np.shape(norm_dist)\n",
    "    flat_dist = norm_dist.flatten()\n",
    "    cdf = np.cumsum(flat_dist)\n",
    "    for n in range(N):\n",
    "        each = {}\n",
    "        r = np.random.random()\n",
    "        k = bisect.bisect(cdf, r)\n",
    "        (t_ind, z_ind) = np.unravel_index(k, dist_shape)\n",
    "        each['t'] = types[t_ind]\n",
    "        each['z'] = np.random.uniform(low=z_bins[z_ind], high=z_bins[z_ind + 1])\n",
    "        out_info.append(each)\n",
    "    return out_info\n",
    "\n",
    "n_sne = 10\n",
    "\n",
    "true_params = sample_discrete(true_n_of_z, n_sne)\n",
    "\n",
    "to_plot = [[d['z'] for d in true_params if d['t'] == types[t]] for t in range(n_types)]\n",
    "for t in range(n_types):\n",
    "    plt.hist(to_plot[t], color=colors[t], alpha=1./3., label=types[t], normed=True)\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'relative rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[the true cosmology, true mu for each t, z, plot hubble diagram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H0 = 72\n",
    "Om0 = 0.3\n",
    "\n",
    "true_cosmo = cosmology.FlatLambdaCDM(H0=H0, Om0=Om0)\n",
    "\n",
    "for n in range(n_sne):\n",
    "    true_params[n]['mu'] = true_cosmo.distmod(true_params[n]['z']).value\n",
    "    \n",
    "to_plot_x = [[d['z'] for d in true_params if d['t'] == types[t]] for t in range(n_types)]\n",
    "to_plot_y = [[d['mu'] for d in true_params if d['t'] == types[t]] for t in range(n_types)]\n",
    "for t in range(n_types):\n",
    "    plt.scatter(to_plot_x[t], to_plot_y[t], color=colors[t], label=types[t])\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$\\mu$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[the confusion matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf_matrix = 0.25 + 0.25 * np.eye(3)#np.ones((n_types, n_types)) / n_types **2\n",
    "assert np.isclose(np.sum(conf_matrix, axis=1).all(), frac_types.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[set up mu parametrization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_mus = n_zs\n",
    "min_mu, max_mu = 35., 45.#min([s['mu'] for s in true_params]), max([s['mu'] for s in true_params])\n",
    "mu_bins = np.linspace(min_mu, max_mu, num=n_mus + 1, endpoint=True)#true_cosmo.distmod(z_bins).value\n",
    "mu_difs = mu_bins[1:] - mu_bins[:-1]\n",
    "mu_dif = np.mean(mu_difs)\n",
    "mu_range = np.max(mu_bins) - np.min(mu_bins)\n",
    "mu_mids = (mu_bins[1:] + mu_bins[:-1]) / 2.\n",
    "\n",
    "z_mu_grid = np.array([[(z, mu) for mu in mu_mids] for z in z_mids])\n",
    "cake_shape = np.shape(z_mu_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[the functions taking true type, true z, and true mu returning p(type, z, mu | hat(t))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ia_Ia_var = np.array([0.01, 0.05])\n",
    "Ibc_Ia_delta = 1.\n",
    "Ibc_Ia_var = np.array([0.01, 0.01])\n",
    "II_Ia_delta = np.mean(mu_mids)\n",
    "II_Ia_var = np.array([0.01, 0.1])\n",
    "\n",
    "def fit_Ia(z, mu):\n",
    "    cake = np.zeros((n_types, n_zs, n_mus))\n",
    "    cake_Ia = sps.multivariate_normal(mean = np.array([z, mu]), cov = Ia_Ia_var * np.eye(2))\n",
    "    [z_samp, mu_samp] = cake_Ia.rvs()\n",
    "    cake_Ia = sps.multivariate_normal(mean = np.array([z_samp, mu_samp]), cov = Ia_Ia_var * np.eye(2))\n",
    "    cake[0] = cake_Ia.pdf(z_mu_grid.reshape(-1, cake_shape[-1])).reshape(cake_shape[:-1])\n",
    "    cake[1] = np.ones(cake_shape[:-1]) / np.prod(cake_shape[:-1])\n",
    "    cake[2] = np.ones(cake_shape[:-1]) / np.prod(cake_shape[:-1])\n",
    "    cake *= conf_matrix[:, 0, np.newaxis, np.newaxis]\n",
    "    return cake\n",
    "    \n",
    "def fit_Ibc(z, mu):\n",
    "    cake = np.zeros((n_types, n_zs, n_mus))\n",
    "    cake_Ia = sps.multivariate_normal(mean = np.array([z, mu - Ibc_Ia_delta]), cov = Ibc_Ia_var * np.eye(2))\n",
    "    [z_samp, mu_samp] = cake_Ia.rvs()\n",
    "    cake_Ia = sps.multivariate_normal(mean = np.array([z_samp, mu_samp]), cov = Ibc_Ia_var * np.eye(2))\n",
    "    cake[0] = cake_Ia.pdf(z_mu_grid.reshape(-1, cake_shape[-1])).reshape(cake_shape[:-1])\n",
    "    cake[1] = np.ones(cake_shape[:-1]) / np.prod(cake_shape[:-1])\n",
    "    cake[2] = np.ones(cake_shape[:-1]) / np.prod(cake_shape[:-1])\n",
    "    cake *= conf_matrix[:, 1, np.newaxis, np.newaxis]\n",
    "    return cake\n",
    "    \n",
    "def fit_II(z, mu):\n",
    "    cake = np.zeros((n_types, n_zs, n_mus))\n",
    "    cake_Ia = sps.multivariate_normal(mean = np.array([z, II_Ia_delta]), cov = II_Ia_var * np.eye(2))\n",
    "    [z_samp, mu_samp] = cake_Ia.rvs()\n",
    "    cake_Ia = sps.multivariate_normal(mean = np.array([z_samp, mu_samp]), cov = II_Ia_var * np.eye(2))\n",
    "    cake[0] = cake_Ia.pdf(z_mu_grid.reshape(-1, cake_shape[-1])).reshape(cake_shape[:-1])\n",
    "    cake[1] = np.ones(cake_shape[:-1]) / np.prod(cake_shape[:-1])\n",
    "    cake[2] = np.ones(cake_shape[:-1]) / np.prod(cake_shape[:-1])\n",
    "    cake *= conf_matrix[:, 2, np.newaxis, np.newaxis]\n",
    "    return cake\n",
    "    \n",
    "def fit_any(true_vals):\n",
    "    if true_vals['t'] == 'Ia':\n",
    "        cake = fit_Ia(true_vals['z'], true_vals['mu'])\n",
    "    if true_vals['t'] == 'Ibc':\n",
    "        cake = fit_Ibc(true_vals['z'], true_vals['mu'])\n",
    "    if true_vals['t'] == 'II':\n",
    "        cake = fit_II(true_vals['z'], true_vals['mu'])\n",
    "    return cake\n",
    "\n",
    "def fit_all(catalog):\n",
    "    dessert = []\n",
    "    for true_vals in catalog:\n",
    "        dessert.append(fit_any(true_vals))\n",
    "    return np.array(dessert)\n",
    "\n",
    "sheet_cake = fit_all(true_params)\n",
    "print(np.shape(sheet_cake))\n",
    "\n",
    "fig = plt.figure(figsize=(n_types*10, n_sne*10))\n",
    "p = 0\n",
    "for s in range(n_sne):\n",
    "    for t in range(n_types):\n",
    "        p += 1\n",
    "        ax = fig.add_subplot(n_sne, n_types, p)\n",
    "        ax.pcolormesh(z_mids, mu_mids, sheet_cake[s][t], cmap='viridis')\n",
    "        ax.scatter(true_params[s]['z'], true_params[s]['mu'], color='k')\n",
    "        ax.set_xticklabels(z_mids)\n",
    "        ax.set_yticklabels(mu_mids)\n",
    "        ax.set_title('true '+true_params[s]['t']+', class '+types[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make p(z)s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pzs = []\n",
    "for s in range(n_sne):\n",
    "    dist = sps.norm(loc = true_params[s]['z'], scale = 0.03)\n",
    "    pz_mean = dist.rvs()\n",
    "    pz = sps.norm(loc = pz_mean, scale = 0.03).pdf(z_mids)\n",
    "    pzs.append(pz)\n",
    "pzs = np.array(pzs)\n",
    "\n",
    "for s in range(n_sne):\n",
    "    plt.plot(z_mids, pzs[s])\n",
    "    plt.vlines(true_params[s]['z'], 0., 15.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[interim priors to make interim posteriors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interim_n_of_z = np.ones((n_types, n_zs))\n",
    "interim_n_of_z /= np.sum(interim_n_of_z * z_difs[np.newaxis, :])\n",
    "assert np.isclose(np.sum(interim_n_of_z * z_difs[np.newaxis, :]), 1.)\n",
    "\n",
    "interim_H0 = 70\n",
    "interim_Om0 = 0.25\n",
    "\n",
    "interim_cosmo = cosmology.FlatLambdaCDM(H0=interim_H0, Om0=interim_Om0)\n",
    "\n",
    "interim_prior = np.zeros((n_types, n_zs, n_mus))\n",
    "for t in range(n_types):\n",
    "    for z in range(n_zs):\n",
    "        mu = interim_cosmo.distmod(z_mids[z]).value\n",
    "        k = bisect.bisect(mu_mids, mu)\n",
    "        interim_prior[t][z][k] += interim_n_of_z[t][z]\n",
    "interim_prior /= mu_difs[np.newaxis, np.newaxis, :]\n",
    "assert np.isclose(np.sum(interim_prior * z_difs[np.newaxis, :, np.newaxis] * mu_difs[np.newaxis, np.newaxis, :]), 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[write data to file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
