{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `scippr` inference module\n",
    "\n",
    "This notebook outlines the `scippr` inference procedure based on hierarchical inference.  To improve performance, all probabilities will be calculated as log probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.cosmology as cosmology\n",
    "from scipy.stats import norm\n",
    "import emcee\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up the parameter space for the latent variables of supernova type $t$ and redshift $z$.  We consider $T=3$ types $\\tau$ and $Z=100$ redshift bins $\\Delta_{\\zeta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = ['Ia', 'Ibc', 'II']\n",
    "n_types = len(types)\n",
    "\n",
    "n_zs = 100\n",
    "redshift_bins = np.linspace(0.01, 1.201, num=n_zs, endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for the latent variable of distance modulus $\\mu$.  We establish $D=100$ bins $\\Delta_{\\nu}$ using a fiducial cosmology with $H_{0}=70\\ km/s/Mpc$ and $\\Omega_{m, 0}=0.3$, knowing that this choice will not affect the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosmo = cosmology.FlatLambdaCDM(H0=70, Om0=0.3)\n",
    "\n",
    "distancemodulus_bins = cosmo.distmod(redshift_bins)\n",
    "n_mus = n_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not sure exactly where to put this function\n",
    "def mu_binner(mu):\n",
    "    \"\"\"\n",
    "    takes a value of mu and returns a vector of length n_mus with 1 in the bin where mu falls and 0 elsewhere\n",
    "    \"\"\"\n",
    "    vector = np.ones(n_mus)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the log-interim posteriors and interim hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce a placeholder for the catalog of log-interim posteriors $\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\underline{\\ell}_{n}, \\vec{m}_{n}, \\vec{\\theta}^{*}, \\underline{\\phi}^{*})]$ over these three latent variables for $N=10$ supernovae $n$.  The log-interim posteriors represent the three-dimensional log-probability distributions over the latent variables conditioned on the observed lightcurves $\\underline{\\ell}_{n}$ and host galaxy photometry $\\vec{m}_{n}$ as well as the interim hyperparameters for the cosmology $\\vec{\\theta}^{*}$ and for the astrophysics $\\underline{\\phi}^{*}$.  The log-interim posteriors will be described in more details in a mock data generation notebook elsewhere.  However, we can say that the catalog shape is a four-dimensional $N\\times T\\times Z\\times D$ array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_SNe = 10\n",
    "\n",
    "lninterimposteriors = np.zeros((n_SNe, n_types, n_zs, n_mus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interim posteriors must always come with the interim hyperparameters $\\vec{\\theta}^{*}$ and $\\underline{\\phi}^{*}$ used to produce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_of_z = np.ones(n_types, n_zs)\n",
    "interimhyperparameters = {'theta': {'H0': 72}, 'phi': np.log(n_of_z)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the log-hyperprior probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in any Bayesian inference, we must choose a hyperprior distribution over the hyperparameters $\\vec{\\theta}$ and $\\underline{\\phi}$ that we wish to estimate.  At this stage we will only attempt to infer $\\vec{\\theta}=H_{0}$.  We will choose a Gaussian hyperprior distribution over the hyperparameter, i.e. $H_{0}\\sim\\mathcal{N}(7\n",
    "0, 2^{2})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priorhyperparameters = {'H0': {'mean':70, 'sigma':2}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we evaluate the log-hyperprior probability $\\ln[p(\\vec{\\theta}, \\underline{\\phi})]$, we will then be evaluating the log-probability of the hyperprior distribution at the given values of the hyperparameters $\\vec{\\theta}$ and $\\underline{\\phi}$.  Thus, the log-hyperprior probability is a scalar as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lnprior(hyperparameters):\n",
    "    H0 = hyperparameters[0]\n",
    "    H0prior = norm.logpdf(H0, loc=priorhyperparameters['H0']['mean'], scale=priorhyperparameters['H0']['sigma'])\n",
    "    return H0prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the log-hyperlikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-hyperlikelihood $\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\vec{\\theta}, \\underline{\\phi})] = \\ln[p(t_{n}, z_{n} | \\underline{\\phi})]+\\ln[p(\\mu_{n} | z_{n}, \\vec{\\theta})]$ is the sum of two terms separable in the hyperparameters.  In our parametrization, the first is derived from a lookup table and the second is a $\\delta$ function located at the `cosmo.distmod()` function evaluated at the given redshift where `cosmo` is defined using the cosmological parameters in $\\vec{\\theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lnhyperlikelihood(hyperparameters):\n",
    "    sample_cosmo = cosmology.FlatLambdaCDM(H0=hyperparameters['theta']['H0'], Om0=0.3)\n",
    "    log_delta = np.log(mu_binner(sample_cosmo.distmod(redshift_bins)))\n",
    "    return hyperparameters['phi'][:, :, np.newaxis] + log_delta[np.newaxis, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we construct the log-posterior probability function, we note that we will be using the log-hyperlikelihood evaluated at the interim hyperparameter values at every evaluation of the log-posterior probability, so we define it as a constant now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lninterimhyperlikelihood = lnhyperlikelihood(interimhyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the log-posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full log-posterior probability takes the following form:\n",
    "\\begin{equation}\n",
    "\\ln[p(\\vec{\\theta}, \\underline{\\phi} | \\{\\underline{\\ell}_{n}, \\vec{m}_{n}\\}_{N})] \\propto \\ln[p(\\vec{\\theta}, \\underline{\\phi})]+\\sum_{n}^{N}\\ \\ln[\\iiint\\ \\exp[\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\underline{\\ell}_{n}, \\vec{m}_{n}, \\vec{\\theta}^{*}, \\underline{\\phi}^{*})]+\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\vec{\\theta}, \\underline{\\phi})]-\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\vec{\\theta}^{*}, \\underline{\\phi}^{*})]]\\ d\\mu_{n}\\ dz_{n}\\ dt_{n}]\n",
    "\\end{equation}\n",
    "In words, that's the sum of the log-prior probability and the sum of the logs of the integrals over the sum of the log-interim posteriors, the log-hyperlikelihood, and the negative log-interim hyperlikelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lnprob(hyperparameters):\n",
    "    return lnprior(hyperparameters) + np.sum(np.log(np.sum(np.sum(np.sum(np.exp(\n",
    "                        lninterimposteriors + lnhyperlikelihood(hyperparameters) - lninterimhyperlikelihood)\n",
    "                                                        , axis=3), axis=2), axis=1)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcrandstep = 10.**-1.\n",
    "nthreads = 1\n",
    "nwalkers = 150\n",
    "nsteps = 2000\n",
    "ninit = 200\n",
    "output_chain = True\n",
    "emcee_chain_output = \"emcee_chain_testing.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_MCMC(theta, lnprob):\n",
    "    init_positions = [np.array(theta) + mcrandstep*np.random.randn(len(theta)) for i in range(int(nwalkers))]\n",
    "    sampler = emcee.EnsembleSampler(int(nwalkers), len(theta), lnprob, threads=int(nthreads))\n",
    "    for i, result in enumerate(sampler.sample(init_positions, iterations=ninit, storechain=False)):\n",
    "        position = result[0]\n",
    "        lnprob_pos = result[1]\n",
    "        if (i+1) % 20 == 0:\n",
    "            print(\"Burn-in: {0:.1f}%, \".format(100 * float(i+1) / ninit))\n",
    "            print datetime.now()\n",
    "        if output_chain:\n",
    "            if i%10 == 0:\n",
    "                f = open(emcee_chain_output, \"a\")\n",
    "                for k in range(position.shape[0]):\n",
    "                    for j in range(position.shape[1]):\n",
    "                        f.write(\"{:+010.5f} \".format(position[k,j]))\n",
    "                    f.write(\"{:+010.5f} \".format(lnprob_pos[k]))\n",
    "                    f.write(\"\\n\")\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lninterimposterior = np.zeros((num_SNe, len(types), len(redshift_bins), len(distancemodulus_bins)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interimtheta = [72]\n",
    "lninterimhyperlikelihood = lnhyperlikelihood(interimtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_MCMC(theta, lnprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
