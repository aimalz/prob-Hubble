{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `scippr` inference module\n",
    "\n",
    "This notebook outlines the `scippr` inference procedure based on hierarchical inference.  To improve performance, all probabilities will be calculated as log probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.cosmology as cosmology\n",
    "import scipy.optimize as spo\n",
    "import scipy.stats as sps\n",
    "from scipy.stats import norm\n",
    "import scipy.linalg as la\n",
    "import emcee\n",
    "from datetime import datetime\n",
    "import hickle\n",
    "import bisect\n",
    "import daft\n",
    "import cProfile\n",
    "import StringIO\n",
    "import sys\n",
    "epsilon = np.log(sys.float_info.epsilon)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc(\"font\", family=\"serif\", size=12)\n",
    "rc(\"text\", usetex=True)\n",
    "colors = 'rbgcymk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scippr` is based on a probabilistic graphical model, illustrated below.  The model has two types of observables, shown in shaded circles, supernova lightcurves $\\underline{\\ell}_{n}$ and host galaxy photometry $\\vec{m}_{n}$.  The parameters, which are by definition not directly observable, are shown in empty circles.  The latent variables of supernova type $t_{n}$, redshift $z_{n}$, and distance modulus $\\mu_{n}$ are parameters over which we will marginalize, without ever directly inferring them, and while all three of them influence $\\underline{\\ell}_{n}$, only $z_{n}$ affects $\\vec{m}_{n}$ in this model.  In other words, _we currently assume no relationship between supernova type and host galaxy photometry, an assumption we may revisit in the future_.  The selection functions parametrized by $\\vec{P}$, $\\vec{V}$, $\\vec{C}$, and $\\vec{M}$ are known constants of the survey symbolized by dots that influence the possible lightcurves and host galaxy photometry that are included in the sample.  The box indicates that the latent variables and the observables are generated independently $N$ times for each supernova in the sample.  The hyperparameters we would like to estimate are the redshift-dependent supernova type proportions $\\underline{\\phi}$ that determine $t_{n}$ and $z_{n}$ and the cosmological parameters $\\vec{\\theta}$ that relate $z_{n}$ to $\\mu_{n}$, which are shared by all $N$ supernovae in the observed sample.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the PGM\n",
    "pgm = daft.PGM([6, 4.5], origin=[0, 0])\n",
    "\n",
    "#desired hyperparameters\n",
    "pgm.add_node(daft.Node(\"cosmology\", r\"$\\vec{\\theta}$\", 2., 4.))\n",
    "pgm.add_node(daft.Node(\"dist\", r\"$\\underline{\\phi}$\", 3.5, 4.))\n",
    "#pgm.add_node(daft.Node(\"rates\", r\"$\\vec{R}$\", 3., 5.5, fixed=True))\n",
    "\n",
    "#latent variables/parameters\n",
    "pgm.add_node(daft.Node(\"distance\", r\"$\\mu_{n}$\", 2., 2.5))\n",
    "pgm.add_node(daft.Node(\"redshift\", r\"$z_{n}$\", 3., 3.))\n",
    "pgm.add_node(daft.Node(\"type\", r\"$t_{n}$\", 4., 2.5))\n",
    "\n",
    "#data\n",
    "pgm.add_node(daft.Node(\"lightcurve\", r\"$\\underline{\\ell}_{n}$\", 2.5, 1., observed=True))\n",
    "pgm.add_node(daft.Node(\"photometry\", r\"$\\vec{m}_{n}$\", 3.5, 1., observed=True))\n",
    "\n",
    "#known constant parameters\n",
    "pgm.add_node(daft.Node(\"lightcurve selection\", r\"$\\vec{P}, \\vec{V}, \\vec{C}$\", 1., 1.75, fixed=True))\n",
    "pgm.add_node(daft.Node(\"photometry selection\", r\"$\\vec{M}$\", 5., 1.75, fixed=True))\n",
    "\n",
    "# Add in the edges.\n",
    "pgm.add_edge(\"dist\", \"type\")\n",
    "pgm.add_edge(\"cosmology\", \"distance\")\n",
    "pgm.add_edge(\"dist\", \"redshift\")\n",
    "pgm.add_edge(\"redshift\", \"distance\")\n",
    "#pgm.add_edge(\"distance\", \"photometry\")\n",
    "pgm.add_edge(\"distance\", \"lightcurve\")\n",
    "pgm.add_edge(\"redshift\", \"photometry\")\n",
    "pgm.add_edge(\"redshift\", \"lightcurve\")\n",
    "pgm.add_edge(\"type\", \"lightcurve\")\n",
    "pgm.add_edge(\"photometry selection\", \"photometry\")\n",
    "pgm.add_edge(\"lightcurve selection\", \"lightcurve\")\n",
    "\n",
    "# plates\n",
    "pgm.add_plate(daft.Plate([1.5, 0.5, 3., 3.], label=r\"$n = 1, \\cdots, N$\"))\n",
    "\n",
    "# Render and save.\n",
    "pgm.render()\n",
    "pgm.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilistic graphical model will guide us in characterizing the posterior distribution $\\ln[p(\\vec{\\theta}, \\underline{\\phi} | \\{\\underline{\\ell}_{n}, \\vec{m}_{n}\\}_{N}, \\vec{P}, \\vec{V}, \\vec{C}, \\vec{M})]$ of the hyperparameters given the observed data, but as a sneak preview, this is the form it will take:\n",
    "\n",
    "\\begin{align}\n",
    "\\ln[p(\\vec{\\theta}, \\underline{\\phi} | \\{\\underline{\\ell}_{n}, \\vec{m}_{n}\\}_{N}, \\vec{P}, \\vec{V}, \\vec{C}, \\vec{M})] \\propto & \\ln[p(\\vec{\\theta}, \\underline{\\phi})]\\\\\n",
    "& +\\sum_{n}^{N}\\ \\ln[\\iiint\\ \\exp[\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\underline{\\ell}_{n}, \\vec{m}_{n}, \\vec{\\theta}^{*}, \\underline{\\phi}^{*}, \\vec{P}, \\vec{V}, \\vec{C}, \\vec{M})]+\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\vec{\\theta}, \\underline{\\phi})]\\\\\n",
    "\\ \\ \\ \\ \\ & -\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\vec{\\theta}^{*}, \\underline{\\phi}^{*})]]\\ d\\mu_{n}\\ dz_{n}\\ dt_{n}]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up the parameter space for the latent variables of supernova type $t$, redshift $z$, and distance modulus $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data.hkl', 'r+') as in_file:\n",
    "    sim_info = hickle.load(in_file)\n",
    "    \n",
    "types = sim_info['types']\n",
    "n_types = len(types)\n",
    "\n",
    "z_bins = sim_info['z_bins']\n",
    "z_difs = z_bins[1:] - z_bins[:-1]\n",
    "z_mids = (z_bins[1:] + z_bins[:-1]) / 2.\n",
    "n_zs = len(z_difs)\n",
    "\n",
    "mu_bins = sim_info['mu_bins']\n",
    "mu_difs = mu_bins[1:] - mu_bins[:-1]\n",
    "mu_mids = (mu_bins[1:] + mu_bins[:-1]) / 2.\n",
    "n_mus = len(mu_difs)\n",
    "\n",
    "def safe_log(arr, threshold=sys.float_info.epsilon):\n",
    "    shape = np.shape(arr)\n",
    "    flat = arr.flatten()\n",
    "    logged = np.log(np.array([max(a, threshold) for a in flat])).reshape(shape)\n",
    "    return logged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the log-interim posteriors and interim hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scippr` requires inputs in the form of catalogs $\\{\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\underline{\\ell}_{n}, \\vec{m}_{n}, \\underline{\\phi}^{*}, \\vec{\\theta}^{*}, \\vec{P}, \\vec{V}, \\vec{C}, \\vec{M})]\\}_{N}$ of interim log-posteriors expressed as `3D` arrays constituting probabilities over $t_{n}$, $z_{n}$, and $\\mu_{n}$, enabling rapid computation of the log-posterior $\\ln[p(\\underline{\\phi}, \\vec{\\theta} | \\{\\underline{\\ell}_{n}, \\vec{m}_{n}\\}_{N}, \\vec{P}, \\vec{V}, \\vec{C}, \\vec{M})$ over the hyperparameters $\\underline{\\phi}$ and $\\vec{\\theta}$ of scientific interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lninterimposteriors = sim_info['interim ln posteriors']\n",
    "(n_SNe, n_types, n_zs, n_mus) = np.shape(lninterimposteriors)\n",
    "\n",
    "# these are going to get a lot narrower\n",
    "fig = plt.figure(figsize=(n_types * len(colors), n_SNe * len(colors)))\n",
    "p = 0\n",
    "for s in range(n_SNe)[:len(colors)]:\n",
    "    for t in range(n_types):\n",
    "        p += 1\n",
    "        plt.subplot(n_SNe, n_types, p)\n",
    "        plt.pcolormesh(z_mids, mu_mids, lninterimposteriors[s][t].T, cmap='viridis')#, vmin = 0., vmax = 3.)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(r'$z$')\n",
    "        plt.ylabel(r'$\\mu$')\n",
    "        plt.axis([z_bins[0], z_bins[-1], mu_bins[0], mu_bins[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interim posteriors must always come with interim hyperparameters specifying $p^{*}(t, z, \\mu)$ used to produce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ln_prior = sim_info['interim ln prior']\n",
    "\n",
    "# interim_n_of_z_hyperparams = interimhyperparameters['phi']\n",
    "\n",
    "# interim_cosmo_hyperparams = interimhyperparameters['theta'][0]#np.array([[interim_H0, interim_Om0], [delta_H0, delta_Om0]])\n",
    "# n_cosmo_hyperparams = len(interim_cosmo_hyperparams)\n",
    "# interim_cosmo_hyperparam_vars = interimhyperparameters['theta'][1]\n",
    "# interim_cosmo_hyperparam_cov = interim_cosmo_hyperparam_vars * np.eye(n_cosmo_hyperparams)\n",
    "# interim_dist = sps.multivariate_normal(mean = interim_cosmo_hyperparams, cov = interim_cosmo_hyperparam_cov)\n",
    "# interim_cosmo = cosmology.FlatLambdaCDM(H0=interim_cosmo_hyperparams[0], Om0=interim_cosmo_hyperparams[1])\n",
    "\n",
    "# # WMAP starting points for optimization\n",
    "# guess_H0 = 70.0\n",
    "# guess_Om0 = 1. - 0.721\n",
    "# ivals_cosmo_hyperparams = np.array([guess_H0, guess_Om0])\n",
    "\n",
    "# def inverter(z, mu):\n",
    "#     def cosmo_helper(hyperparams):\n",
    "#         return np.array([abs(cosmology.FlatLambdaCDM(H0=hyperparams[0], Om0=hyperparams[1]).distmod(z).value - mu)])\n",
    "#     solved_cosmo = spo.minimize(cosmo_helper, ivals_cosmo_hyperparams, method=\"Nelder-Mead\", options={\"maxfev\": 1e5, \"maxiter\":1e5})\n",
    "#     ln_prob = interim_dist.logpdf(solved_cosmo.x)\n",
    "#     return ln_prob#max(prob, sys.float_info.epsilon)\n",
    "\n",
    "# # note the approximation of cdf[z_min, z_max] = pdf[z_mid]\n",
    "# interim_sheet = np.zeros((n_zs, n_mus))\n",
    "# for z in range(n_zs):\n",
    "#     for mu in range(n_mus):\n",
    "#         ln_prob = inverter(z_mids[z], mu_mids[mu])\n",
    "#         interim_sheet[z][mu] = ln_prob\n",
    "# interim_ln_prior = interim_n_of_z_hyperparams[:, np.newaxis] + interim_sheet[np.newaxis, :]\n",
    "# interim_prior = np.exp(interim_ln_prior)\n",
    "# interim_prior /= np.sum(interim_prior * z_difs[np.newaxis, :, np.newaxis] * mu_difs[np.newaxis, np.newaxis, :])\n",
    "# interim_ln_prior = safe_log(interim_prior)\n",
    "# assert np.isclose(np.sum(interim_prior * z_difs[np.newaxis, :, np.newaxis] * mu_difs[np.newaxis, np.newaxis, :]), 1.)\n",
    "\n",
    "# the interim prior and truth are way too close to each other. . . but that's realistic\n",
    "fig = plt.figure(figsize=(n_types*len(colors), len(colors)))\n",
    "for t in range(n_types):\n",
    "    plt.subplot(1, n_types, t+1)\n",
    "    plt.pcolormesh(z_mids, mu_mids, interim_ln_prior[t].T, cmap='viridis')#, vmin = 0., vmax = 3.)\n",
    "    plt.title('SN '+types[t]+' interim prior distribution')\n",
    "    plt.xlabel(r'$z$')\n",
    "    plt.ylabel(r'$\\mu$')\n",
    "    plt.legend(loc='lower right', fontsize='small')\n",
    "    plt.axis([z_bins[0], z_bins[-1], mu_bins[0], mu_bins[-1]])\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the log-hyperprior probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in any Bayesian inference, we must choose a hyperprior distribution over the hyperparameters $\\vec{\\theta}$ and $\\underline{\\phi}$ that we wish to estimate.  At this stage we will only attempt to infer $\\vec{\\theta}=(H_{0}, \\Omega_{m0})$.  We will choose a pair of truncated Gaussians as the hyperprior distribution over the hyperparameters (i.e. assuming $H_{0}$ and $\\Omega_{m, 0}$ are independent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class indie_dist(object):\n",
    "    def __init__(self, in_dists):\n",
    "        self.dists = in_dists\n",
    "        self.n_dists = len(self.dists)\n",
    "    def rvs(self, n_samps = 1):\n",
    "        samps = []\n",
    "        for d in range(self.n_dists):\n",
    "            samps.append(self.dists[d].rvs(n_samps))\n",
    "        return(np.array(samps).T)\n",
    "    def logpdf(self, locs):\n",
    "        n_items = len(locs)\n",
    "        lnprobs = np.ones(n_items)\n",
    "        locs = locs.T\n",
    "        for d in range(self.n_dists):\n",
    "            lnprobs += self.dists[d].logpdf(locs[d])\n",
    "        return(lnprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WMAP, with 10 * errors so we can see what's going on in crappy plots\n",
    "wmap_H0 = 70.0\n",
    "delta_H0 = 2.2 * 10.\n",
    "wmap_Om0 = 1. - 0.721\n",
    "delta_Om0 = 0.025 * 10.\n",
    "\n",
    "[H0_mean, H0_std] = [wmap_H0, delta_H0]\n",
    "min_H0, max_H0 = 50, 100\n",
    "H0_low, H0_high = (min_H0 - H0_mean) / H0_std, (max_H0 - H0_mean) / H0_std\n",
    "H0_dist = sps.truncnorm(H0_low, H0_high, loc = H0_mean, scale = H0_std)\n",
    "\n",
    "[Om0_mean, Om0_std] = [wmap_Om0, delta_Om0]\n",
    "min_Om0, max_Om0 = 0., 1.\n",
    "Om0_low, Om0_high = (min_Om0 - Om0_mean) / Om0_std, (max_Om0 - Om0_mean) / Om0_std\n",
    "Om0_dist = sps.truncnorm(Om0_low, Om0_high, loc = Om0_mean, scale = Om0_std)\n",
    "\n",
    "prior_cosmo_hyperparams = np.array([H0_dist.rvs(), Om0_dist.rvs()])\n",
    "cosmo_param_names = [r'$H_{0}$', r'$\\Omega_{m0}$']\n",
    "n_cosmo_hyperparams = len(prior_cosmo_hyperparams)\n",
    "# prior_cosmo_hyperparam_vars = interim_cosmo_hyperparam_vars\n",
    "# prior_cosmo_dist = sps.multivariate_normal(mean = prior_cosmo_hyperparams, cov = prior_cosmo_hyperparam_vars)\n",
    "prior_cosmo_dist = indie_dist([H0_dist, Om0_dist])\n",
    "prior_cosmo = cosmology.FlatLambdaCDM(H0=prior_cosmo_hyperparams[0], Om0=prior_cosmo_hyperparams[1])\n",
    "\n",
    "# # prior on phi is gaussian about flat in log space\n",
    "# prior_mean = np.ones((n_types, n_zs)) / n_types\n",
    "# prior_mean /= np.sum(prior_mean * z_difs[np.newaxis, :])\n",
    "# assert np.isclose(np.sum(prior_mean * z_difs[np.newaxis, :]), 1.)\n",
    "# prior_mean = safe_log(prior_mean.flatten())\n",
    "# prior_sigmas = np.array([0.5, 1., 0.25])\n",
    "# prior_covariance = la.block_diag(prior_sigmas[0] * np.eye(n_zs), prior_sigmas[1] * np.eye(n_zs), prior_sigmas[2] * np.eye(n_zs))\n",
    "# # prior_n_of_z_hyperparams = [prior_mean, prior_sigmas]\n",
    "# prior_n_of_z_dist = sps.multivariate_normal(mean = prior_mean, cov = prior_covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we evaluate the log-hyperprior probability $\\ln[p(\\vec{\\theta}, \\underline{\\phi})]$, we will then be evaluating the log-probability of the hyperprior distribution at the given values of the hyperparameters $\\vec{\\theta}$ and $\\underline{\\phi}$.  Thus, the log-hyperprior probability is a scalar as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lnprior(hyperparameters):\n",
    "    cosmo_hyperparameters = hyperparameters#['theta']\n",
    "#     dist_hyperparameters = hyperparameters['phi']\n",
    "    cosmo_prior_prob = prior_cosmo_dist.logpdf(cosmo_hyperparameters)\n",
    "#     dist_prior_prob = prior_n_of_z.logpdf(dist_hyperparameters.flatten())\n",
    "    return cosmo_prior_prob # + dist_prior_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the log-hyperlikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-hyperlikelihood $\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\vec{\\theta}, \\underline{\\phi})] = \\ln[p(t_{n}, z_{n} | \\underline{\\phi})]+\\ln[p(\\mu_{n} | z_{n}, \\vec{\\theta})]$ is the sum of two terms separable in the hyperparameters.  In our parametrization, the first is derived from a constant lookup table that can be neglected for now and the second is a $\\delta$ function located at the `cosmo.distmod()` function evaluated at the given redshift where `cosmo` is defined using the cosmological parameters in $\\vec{\\theta}$.  We will at this stage need to introduce a function mapping redshifts into distance moduli under a given cosmology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lnhyperlikelihood(hyperparameters):\n",
    "    cosmo_hyperparameters = hyperparameters#['theta']\n",
    "#     dist_hyperparameters = hyperparameters['phi']\n",
    "    if cosmo_hyperparameters[1] >= 0. and cosmo_hyperparameters[1] <= 1.:\n",
    "        sample_cosmo = cosmology.FlatLambdaCDM(H0=cosmo_hyperparameters[0], Om0=cosmo_hyperparameters[1])\n",
    "        log_delta = mu_binner(sample_cosmo.distmod(z_mids).value)\n",
    "        return log_delta[np.newaxis, np.newaxis, :] # + dist_hyperparameters[:, :, np.newaxis]\n",
    "    else:\n",
    "        return epsilon\n",
    "\n",
    "def mu_binner(mus):\n",
    "    matrix = []\n",
    "    for mu in mus:\n",
    "        vector = np.zeros(n_mus)\n",
    "        ind = bisect.bisect(mu_bins[:-1], mu) - 1\n",
    "        vector[ind] += 1. / mu_difs[ind]\n",
    "        matrix.append(vector)\n",
    "    return safe_log(np.array(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we construct the log-posterior probability function, we note that we will be using the log-hyperlikelihood evaluated at the interim hyperparameter values at every evaluation of the log-posterior probability, so we define it as a constant now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for_interimhyperlikelihood = {}\n",
    "# for_interimhyperlikelihood['theta'] = interim_cosmo_hyperparams\n",
    "# for_interimhyperlikelihood['phi'] = interimhyperparameters['phi']\n",
    "# lninterimhyperlikelihood = lnhyperlikelihood(for_interimhyperlikelihood)\n",
    "lninterimhyperlikelihood = interim_ln_prior#lnhyperlikelihood(interim_cosmo_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the log-posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full log-posterior probability takes the following form:\n",
    "\\begin{equation}\n",
    "\\ln[p(\\vec{\\theta}, \\underline{\\phi} | \\{\\underline{\\ell}_{n}, \\vec{m}_{n}\\}_{N})] \\propto \\ln[p(\\vec{\\theta}, \\underline{\\phi})]+\\sum_{n}^{N}\\ \\ln[\\iiint\\ \\exp[\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\underline{\\ell}_{n}, \\vec{m}_{n}, \\vec{\\theta}^{*}, \\underline{\\phi}^{*})]+\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\vec{\\theta}, \\underline{\\phi})]-\\ln[p(t_{n}, z_{n}, \\mu_{n} | \\vec{\\theta}^{*}, \\underline{\\phi}^{*})]]\\ d\\mu_{n}\\ dz_{n}\\ dt_{n}]\n",
    "\\end{equation}\n",
    "In words, that's the sum of the log-prior probability and the sum of the logs of the integrals over the sum of the log-interim posteriors, the log-hyperlikelihood, and the negative log-interim hyperlikelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lnposterior(hyperparameters):\n",
    "    in_exp = lninterimposteriors + lnhyperlikelihood(hyperparameters) - lninterimhyperlikelihood\n",
    "    in_log = np.sum(np.sum(np.sum(np.exp(in_exp), axis=3), axis=2), axis=1)\n",
    "    in_sum = np.log(in_log)\n",
    "    return np.sum(in_sum, axis=0)\n",
    "\n",
    "def lnhyperposterior(hyperparameters):\n",
    "    return lnprior(hyperparameters) + lnposterior(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcrandstep = 10.**-1.\n",
    "nthreads = 1\n",
    "nwalkers = 100\n",
    "nsteps = 1000\n",
    "ninit = 100\n",
    "output_chain = True\n",
    "emcee_chain_output = \"emcee_chain_testing.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will need to do gibbs sampling to get phi\n",
    "def run_MCMC(lnprob):\n",
    "#     init_positions = []# [np.array(theta) + mcrandstep*np.random.randn(len(theta)) for i in range(int(nwalkers))]\n",
    "#     for w in range(nwalkers):\n",
    "#         hyperparam_dict = {}\n",
    "#         hyperparam_dict['theta'] = prior_cosmo_dist.rvs()\n",
    "# #         hyperparam_dict['phi'] = prior_n_of_z_dist.rvs()\n",
    "#         init_positions.append(hyperparam_dict)\n",
    "#     init_vals = prior_cosmo_dist.rvs()\n",
    "#     print(init_vals)\n",
    "#     init_H0_dist = sps.truncnorm(H0_low, H0_high, loc = init_vals[0][0], scale = H0_std)\n",
    "#     init_Om0_dist = sps.truncnorm(Om0_low, Om0_high, loc = init_vals[0][1], scale = Om0_std)\n",
    "#     init_dist = indie_dist([init_H0_dist, init_Om0_dist])\n",
    "    init_positions = prior_cosmo_dist.rvs(nwalkers)#init_dist.rvs(nwalkers)\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, n_cosmo_hyperparams, lnprob)\n",
    "    burning = sampler.run_mcmc(init_positions, ninit)\n",
    "    burn_in = sampler.chain\n",
    "    new_init_positions = np.array([item[-1] for item in burn_in])\n",
    "    sampler.reset()\n",
    "    output = sampler.run_mcmc(new_init_positions, nsteps)\n",
    "    chain = sampler.chain\n",
    "    probs = sampler.lnprobability\n",
    "    fracs = sampler.acceptance_fraction\n",
    "#     acors = sampler.acor(chains)\n",
    "    mcmc_outputs = {}\n",
    "    mcmc_outputs['chain'] = chain\n",
    "    mcmc_outputs['probs'] = probs\n",
    "    mcmc_outputs['fracs'] = fracs\n",
    "#     mcmc_outputs['acors'] = acors\n",
    "    return mcmc_outputs\n",
    "#     for i, result in enumerate(sampler.run_mcmc(init_positions, ninit, storechain=False)):\n",
    "#         position = result[0]\n",
    "#         lnprob_pos = result[1]\n",
    "#         if (i+1) % 20 == 0:\n",
    "#             print(\"Burn-in: {0:.1f}%, \".format(100 * float(i+1) / ninit))\n",
    "#             print datetime.now()\n",
    "#         if output_chain:\n",
    "#             if i%10 == 0:\n",
    "#                 f = open(emcee_chain_output, \"a\")\n",
    "#                 for k in range(position.shape[0]):\n",
    "#                     for j in range(position.shape[1]):\n",
    "#                         f.write(\"{:+010.5f} \".format(position[k,j]))\n",
    "#                     f.write(\"{:+010.5f} \".format(lnprob_pos[k]))\n",
    "#                     f.write(\"\\n\")\n",
    "#                 f.close()\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "results = run_MCMC(lnhyperposterior)\n",
    "\n",
    "pr.disable()\n",
    "s = StringIO.StringIO()\n",
    "sortby = 'cumtime'\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(nwalkers):\n",
    "    to_plot = results['probs'][w]\n",
    "    plt.plot(-1.*to_plot, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(-1./results['probs'].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(nwalkers):\n",
    "    to_plot = results['chain'][w].T\n",
    "    plt.scatter(to_plot[0], to_plot[1], alpha=0.01)#1./np.mean(results['probs'][w]))\n",
    "plt.scatter(67.9, 1. - 0.693, color='r')\n",
    "plt.xlabel(cosmo_param_names[0])\n",
    "plt.ylabel(cosmo_param_names[1])\n",
    "plt.savefig('bananas.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../truth.hkl', 'r+') as true_file:\n",
    "    true_info = hickle.load(true_file)\n",
    "    \n",
    "true_phi = true_info['phi']\n",
    "true_theta = true_info['theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(n_cosmo_hyperparams * len(colors), len(colors)))\n",
    "priorvals = [H0_mean, Om0_mean]\n",
    "for p in range(n_cosmo_hyperparams):\n",
    "    plt.subplot(1, n_cosmo_hyperparams, p + 1)\n",
    "    for w in range(nwalkers):\n",
    "        to_plot = results['chain'][w].T\n",
    "        plt.plot(to_plot[p], alpha=0.1)#1./np.mean(results['probs'][w]))#, to_plot[1])\n",
    "    plt.plot([true_theta[p]] * nsteps, c='k', linewidth=2)\n",
    "    plt.xlabel('sample number')\n",
    "    plt.ylabel(cosmo_param_names[p])\n",
    "plt.savefig('evolution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
